{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3041516f-3aa2-4e30-bb7f-f4becb825103",
   "metadata": {},
   "source": [
    "## Modify restart files\n",
    "\n",
    "The script modifies all restart files in a directory. It applies the same modification to all restart files in the direcotry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37feb262-d066-4d99-8203-b3d3ac93e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append('/glade/u/home/adamhb/Earth-System-Model-Tools/')\n",
    "import esm_tools\n",
    "import os\n",
    "pd.set_option('display.max_rows', 1500)\n",
    "pd.set_option('display.max_columns', 1500)\n",
    "np.set_printoptions(threshold=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "901ad20b-c932-4ead-9581-e06ed0edd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the restart files you want to modify\n",
    "path_to_rest_files = '/glade/derecho/scratch/adamhb/f1870-1951_043024-1870-1951_-17e2acb6a_FATES-1449c787/run'\n",
    "\n",
    "\n",
    "#/glade/derecho/scratch/adamhb/sup_043024-1951-2020_-17e2acb6a_FATES-1449c787/rest/2015-01-01-00000\n",
    "\n",
    "do_logging = True\n",
    "do_treatment = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed315fa7-e16a-43f9-a730-672232d255d3",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec7202f3-1465-4a08-80e2-382f910c2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_multi_dim_variable_to_netcdf(file_path, variable_name, new_value):\n",
    "    with nc4.Dataset(file_path, 'r+') as dataset:\n",
    "        if variable_name in dataset.variables:\n",
    "            # Access the variable\n",
    "            variable = dataset.variables[variable_name]\n",
    "\n",
    "            # Assign a value\n",
    "            # The way you assign depends on the shape and dimensions of the variable\n",
    "            # For a single-value variable:\n",
    "\n",
    "            variable[...] = new_value  # Replace new_value with the value you want to assign\n",
    "            #print(\"Changed {} to {}\".format(variable_name,new_value))\n",
    "            # For a multi-dimensional variable, specify indices or slices\n",
    "            # Example for a 2D variable (like temperature at a specific time and place):\n",
    "            # variable[time_index, place_index] = new_value\n",
    "\n",
    "            #print(f\"Value {new_value} assigned to {variable_name}.\")\n",
    "        else:\n",
    "            print(f\"Variable {variable_name} not found in the dataset.\")\n",
    "\n",
    "\n",
    "\n",
    "def find_matching_files(directory):\n",
    "    \"\"\"\n",
    "    Finds and returns a list of file names in the specified directory that contain\n",
    "    both 'clm2_' and '.r.' in their file names.\n",
    "\n",
    "    :param directory: String, the path to the directory where the files are located\n",
    "    :return: List of strings, the file names that match the criteria\n",
    "    \"\"\"\n",
    "    matching_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if \"clm2_\" in filename and \".r.\" in filename:\n",
    "            matching_files.append(filename)\n",
    "    return matching_files\n",
    "\n",
    "def treat_forest(path_to_rest_file,pfts_to_treat,max_size_to_treat,cwd_scalar):\n",
    "\n",
    "    '''\n",
    "    Forest restoration treatment\n",
    "    '''\n",
    "\n",
    "    rest_file = xr.open_dataset(path_to_rest_file,decode_times=False)\n",
    "    df = pd.DataFrame({'pft':rest_file.fates_pft.values,'n':rest_file.fates_nplant.values,\n",
    "                       'dbh':rest_file.fates_dbh,'cwd':rest_file.fates_cwdagin_vec_001,\n",
    "                       'leaf_litt':rest_file.fates_leaf_fines_vec_001})\n",
    "    \n",
    "    \n",
    "    # Remove trees\n",
    "    not_shrub = df['pft'].isin(pfts_to_treat)\n",
    "    small_trees = df['dbh'] < max_size_to_treat\n",
    "    df['nplant_treated'] = np.where((not_shrub) & (small_trees), 0, df['n'])\n",
    "\n",
    "    # Remove CWD and leaf litter\n",
    "    df['cwd'] = df['cwd'] * cwd_scalar\n",
    "    df['leaf_litt'] = df['leaf_litt'] * cwd_scalar\n",
    "    \n",
    "    #print(len(df.loc[(not_shrub) & (small_trees)]),'cohorts remain')\n",
    "\n",
    "\n",
    "    #Reassign\n",
    "    assign_multi_dim_variable_to_netcdf(path_to_rest_file,\"fates_nplant\",  df['nplant_treated'].values)\n",
    "    assign_multi_dim_variable_to_netcdf(path_to_rest_file,\"fates_cwdagin_vec_001\",  df['cwd'].values)\n",
    "    assign_multi_dim_variable_to_netcdf(path_to_rest_file,\"fates_leaf_fines_vec_001\",  df['leaf_litt'].values)\n",
    "\n",
    "    return df\n",
    "\n",
    "def log_forest(path_to_rest_file):\n",
    "\n",
    "    '''\n",
    "    Forest restoration treatment\n",
    "    '''\n",
    "\n",
    "    rest_file = xr.open_dataset(path_to_rest_file,decode_times=False)\n",
    "    df = pd.DataFrame({'pft':rest_file.fates_pft.values,'n':rest_file.fates_nplant.values,\n",
    "                       'dbh':rest_file.fates_dbh,'cwd':rest_file.fates_cwdagin_vec_001,\n",
    "                       'leaf_litt':rest_file.fates_leaf_fines_vec_001})\n",
    "    \n",
    "    \n",
    "    pine = df['pft'] == 1.0\n",
    "    cedar = df['pft'] == 2.0\n",
    "    fir = df['pft'] == 3.0\n",
    "    big_tree = df['dbh'] > 75\n",
    "    small_tree = df['dbh'] < 45\n",
    "    medium_tree = (df['dbh'] >= 45) & (df['dbh'] <= 75)\n",
    "\n",
    "    # Log all large conifers (> 75 cm dbh)\n",
    "\n",
    "    #print(sum((pine | cedar | fir) & big_tree))\n",
    "    df['nplant_logged'] = np.where( (pine | cedar | fir) & big_tree, 0, df['n'])\n",
    "\n",
    "    # Log 73% of medium pines\n",
    "    df['nplant_logged'] = np.where(pine & medium_tree, (1.0-0.73) * df['n'], df['nplant_logged'])\n",
    "\n",
    "    # Log 13% of medium cedars\n",
    "    df['nplant_logged'] = np.where(cedar & medium_tree, (1.0-0.13) * df['n'], df['nplant_logged'])\n",
    "\n",
    "    # Log 33% of medium firs\n",
    "    df['nplant_logged'] = np.where(fir & medium_tree, (1.0-0.33) * df['n'], df['nplant_logged'])\n",
    "\n",
    "    #Reassign\n",
    "    assign_multi_dim_variable_to_netcdf(path_to_rest_file,\"fates_nplant\",  df['nplant_logged'].values)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad4e787e-2366-4441-b9b0-cd5e02cfbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = '/glade/derecho/scratch/adamhb/f1870-1951_043024-1870-1951_-17e2acb6a_FATES-1449c787/run/test/CZ2_equilibrium_700yrs_042524_01_-17e2acb6a_FATES-1449c787.clm2_0001.r.1620-01-01-00000.nc'\n",
    "# original_file = '/glade/derecho/scratch/adamhb/f1870-1951_043024-1870-1951_-17e2acb6a_FATES-1449c787/run/CZ2_equilibrium_700yrs_042524_01_-17e2acb6a_FATES-1449c787.clm2_0001.r.1620-01-01-00000.nc'\n",
    "\n",
    "\n",
    "# test_data = xr.open_dataset(test_file,decode_times=False)\n",
    "# orig_data = xr.open_dataset(original_file,decode_times=False)\n",
    "\n",
    "# pd.DataFrame('orig':orig_data.fates_nplant.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e210f56-9117-441e-9b5f-93de3186d502",
   "metadata": {},
   "source": [
    "## Apply logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb6b214f-57de-4687-96ab-9c379c489888",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_logging == True:\n",
    "\n",
    "    files_to_treat = sorted(find_matching_files(path_to_rest_files))\n",
    "    paths_files_to_treat = [os.path.join(path_to_rest_files,f) for f in files_to_treat]\n",
    "    \n",
    "    for file in paths_files_to_treat:\n",
    "        log_forest(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fee58-a164-4c8b-b250-8f3f1fe37269",
   "metadata": {},
   "source": [
    "## Apply treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29afafbb-755d-4d31-88e8-8242a4120820",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_treatment == True:\n",
    "    files_to_treat = sorted(find_matching_files(path_to_rest_files))\n",
    "    paths_files_to_treat = [os.path.join(path_to_rest_files,f) for f in files_to_treat]\n",
    "    \n",
    "    for file in paths_files_to_treat:\n",
    "        treat_forest(path_to_rest_file = file,pfts_to_treat=[1.0,2.0,3.0,5.0],max_size_to_treat = 40.0,cwd_scalar = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env4_work",
   "language": "python",
   "name": "env4_work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
