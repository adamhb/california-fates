{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a7bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = \"derecho\" #\"laptop_Z30\" or \"derecho\"\n",
    "\n",
    "if machine == \"laptop_Z30\":\n",
    "    path_to_base_param_files_root = '/home/adamhb/gdrive/postdoc/parameters'\n",
    "    path_to_ensemble_param_files_root = '/home/adamhb/gdrive/postdoc/parameters/ensemble_1280_041724'\n",
    "    path_to_ca_fates = '/home/adamhb/gdrive/postdoc/california-fates'\n",
    "    path_to_esm_tools = '/home/adamhb/gdrive/FATES/Earth-System-Model-Tools'\n",
    "    \n",
    "if machine == \"derecho\":\n",
    "    path_to_base_param_files_root = '/glade/u/home/adamhb/ahb_params/fates_api_25'\n",
    "    path_to_ensemble_param_files_root = '/glade/u/home/adamhb/ahb_params/fates_api_25/ensembles/'\n",
    "    path_to_ca_fates = '/glade/u/home/adamhb/california-fates/'\n",
    "    path_to_esm_tools = '/glade/u/home/adamhb/Earth-System-Model-Tools/'\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import cross_val_predict\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "# import tensorflow\n",
    "# import keras\n",
    "# from keras import models\n",
    "# from keras import layers\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import qmc\n",
    "pd.set_option('display.max_rows', 500) \n",
    "import shutil\n",
    "import netCDF4 as nc4\n",
    "import sys\n",
    "sys.path.append(\"/glade/u/home/adamhb/california-fates/ensemble_tools/\")\n",
    "sys.path.append(path_to_esm_tools)\n",
    "import esm_tools\n",
    "import modp as mp\n",
    "from scipy.io import netcdf as nc\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470988e",
   "metadata": {},
   "source": [
    "## Specify paths and load emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06787ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameter ranges\n",
    "param_ranges_full = pd.read_csv(os.path.join(path_to_ca_fates,'parameter_ranges/param_range_archive/param_ranges_042324.csv'))\n",
    "#param_ranges_full = pd.read_csv(os.path.join(path_to_ca_fates,'parameter_ranges/param_range_archive/param_ranges_100223.csv'))\n",
    "\n",
    "# The parameter file used for parameter values that don't vary in the ensemble \n",
    "base_param_file_name = 'ca_ahb_5pfts_041624.nc'\n",
    "\n",
    "# New param file name prefix for the parameter files that do vary\n",
    "file_name_prefix = 'ca_5pfts_100523'\n",
    "\n",
    "# Instances per case\n",
    "inst_per_case = 128\n",
    "\n",
    "# Cases\n",
    "n_cases = 20\n",
    "\n",
    "target_ensemble_size = inst_per_case * n_cases\n",
    "\n",
    "# Prefix for subdirectories where param files for the ensemble are kept\n",
    "param_files_subdir_prefix = f'afterOakFix_{target_ensemble_size}_042323'\n",
    "\n",
    "# How large should each lhs sample be in the generator\n",
    "batch_size = target_ensemble_size\n",
    "seed = 18\n",
    "\n",
    "#path_DNN_NFailed_PFTs = os.path.join(path_to_ca_fates,'ml_emulators/saved_models/DNN_NFailed_110323_v1.h5')\n",
    "#DNN_NFailed_PFTs = keras.models.load_model(path_DNN_NFailed_PFTs)\n",
    "#DNN_NFailed_PFTs = tf.keras.models.load_model(path_DNN_NFailed_PFTs)\n",
    "#path_to_ensemble_data = os.path.join(path_to_ca_fates,'ml_emulators/ML_training_data_110323.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ebc4da",
   "metadata": {},
   "source": [
    "## Check that saved model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9192d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df = pd.read_csv(path_to_ensemble_data)\n",
    "# raw_df.info()\n",
    "# print(\"\\n\")\n",
    "\n",
    "# # Drop first column\n",
    "# raw_df.drop(columns=raw_df.columns[0], axis=1, inplace=True)\n",
    "# print(list(raw_df.columns))\n",
    "\n",
    "# df = raw_df.copy()\n",
    "# df.fillna(0, inplace=True)\n",
    "\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# split = StratifiedShuffleSplit(n_splits=1, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# # Split the data into training and test sets, maintaining an equal proportion of veg and non-veg labels in each.\n",
    "# for train_index, test_index in split.split(df, df['FailedPFTs']):\n",
    "#     train_set = df.iloc[train_index]\n",
    "#     test_set = df.iloc[test_index]\n",
    "\n",
    "# X_cols = train_set.columns[train_set.columns.str.contains('fates')]\n",
    "# train_X = train_set[X_cols]\n",
    "# test_X = test_set[X_cols]\n",
    "\n",
    "# #Create vars to be predicted\n",
    "# train_y_failedPFTs = train_set[\"FailedPFTs\"].copy()\n",
    "\n",
    "# test_y_failedPFTs = test_set[\"FailedPFTs\"].copy()\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # This is for if I need to define a custom data transformation function\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# # Data transformation pipeline\n",
    "# transformation_pipeline = Pipeline([\n",
    "#         ('std_scaler', StandardScaler()), # Scale the data by substracting mean and dividing by sigma\n",
    "#     ])\n",
    "\n",
    "# # Apply transformation pipeline to training data\n",
    "# X = transformation_pipeline.fit_transform(train_X)\n",
    "\n",
    "# # Apply to test data\n",
    "# X_test = transformation_pipeline.fit_transform(test_X)\n",
    "\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "# loss, accuracy = DNN_NFailed_PFTs.evaluate(X_test, test_y_failedPFTs)\n",
    "# print(\"Test Loss:\", loss)\n",
    "# print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# probabilities = DNN_NFailed_PFTs.predict(X_test)\n",
    "# y_pred = np.argmax(probabilities, axis=1)\n",
    "# print(y_pred)\n",
    "\n",
    "# target_names = [str(i) + \"Failed\" for i in range(5)]\n",
    "\n",
    "# # Compute the confusion matrix\n",
    "# cm = confusion_matrix(test_y_failedPFTs, y_pred)\n",
    "\n",
    "# # Display the confusion matrix using Seaborn\n",
    "# plt.figure(figsize=(6, 5))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "\n",
    "# # Optionally, display the classification report for more detailed metrics\n",
    "# print(classification_report(test_y_failedPFTs, y_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0776702",
   "metadata": {},
   "source": [
    "## Load parameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d383648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 55\n",
      "Number of pfts: 5\n",
      "Param names: ['fates_recruit_seed_alloc_mature', 'fates_recruit_seed_alloc_mature', 'fates_recruit_seed_alloc_mature', 'fates_recruit_seed_dbh_repro_threshold', 'fates_recruit_seed_dbh_repro_threshold', 'fates_fire_bark_scaler', 'fates_fire_alpha_SH', 'fates_fire_alpha_SH', 'fates_fire_alpha_SH', 'fates_fire_drying_ratio', 'fates_fire_nignitions', 'fates_mort_bmort', 'fates_mort_bmort', 'fates_leaf_slatop', 'fates_leaf_slatop', 'fates_leaf_slatop', 'fates_leaf_vcmax25top', 'fates_leaf_vcmax25top', 'fates_leaf_vcmax25top', 'fates_fire_frac_resprout', 'fates_fire_frac_resprout', 'fates_frag_seed_decay_rate', 'fates_frag_seed_decay_rate', 'fates_frag_seed_decay_rate', 'fates_recruit_seed_germination_rate', 'fates_recruit_seed_germination_rate', 'fates_recruit_seed_germination_rate', 'fates_disturbance_germ', 'fates_turnover_branch', 'fates_turnover_branch', 'fates_turnover_leaf', 'fates_turnover_leaf', 'fates_turnover_leaf', 'fates_nonhydro_smpsc', 'fates_nonhydro_smpsc', 'fates_nonhydro_smpsc', 'fates_nonhydro_smpsc', 'fates_nonhydro_smpsc', 'fates_mort_hf_sm_threshold', 'fates_recruit_inter_patch_disp_frac', 'fates_frag_maxdecomp', 'fates_alloc_storage_cushion', 'fates_grperc', 'fates_stoich_nitr', 'fates_stoich_nitr', 'fates_stoich_nitr', 'fates_mort_ip_size_senescence', 'fates_mort_ip_age_senescence', 'fates_allom_d2ca_coefficient_max', 'fates_allom_d2ca_coefficient_max', 'fates_allom_d2ca_coefficient_max', 'fates_allom_agb1', 'fates_allom_agb1', 'fates_mort_scalar_cstarvation', 'fates_mort_scalar_hydrfailure']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55 entries, 0 to 91\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pft_ineq   55 non-null     object \n",
      " 1   param      55 non-null     object \n",
      " 2   value_min  55 non-null     float64\n",
      " 3   value_max  55 non-null     float64\n",
      " 4   pft        55 non-null     int64  \n",
      " 5   organ      4 non-null      float64\n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "pft_names = ['pine','cedar','fir','shrub','oak']\n",
    "param_ranges_full = param_ranges_full[['pft_ineq','param', 'value_min', 'value_max', 'pft', 'organ']]\n",
    "\n",
    "# Define params that we are going to sample from the LHS\n",
    "param_ranges = param_ranges_full.loc[param_ranges_full['pft_ineq'] == 'FALSE']\n",
    "\n",
    "# Define params that we are going to alter using pft-inequalities\n",
    "param_ranges_inequalities = param_ranges_full.loc[param_ranges_full['pft_ineq'] != 'FALSE']\n",
    "param_ranges_inequalities = param_ranges_inequalities.dropna(how=\"all\")\n",
    "\n",
    "# Make sure min and max are floats\n",
    "convert_dict = {'value_min': float,\n",
    "                'value_max': float}\n",
    "\n",
    "param_ranges = param_ranges.astype(convert_dict)\n",
    "\n",
    "# number of parameters\n",
    "n_params = len(param_ranges)\n",
    "print(\"Number of params:\",n_params)\n",
    "\n",
    "# number of PFTs - '0' is global so subtract one\n",
    "n_pfts = max(len(pd.unique(param_ranges['pft'])) - 1, 1)\n",
    "print(\"Number of pfts:\", n_pfts)\n",
    "\n",
    "param_names = list(param_ranges.param)\n",
    "print(\"Param names:\",param_names)\n",
    "pfts = list(param_ranges.pft)\n",
    "organs = list(param_ranges.organ)\n",
    "param_ranges.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee5487",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c98cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_angle_brackets(s):\n",
    "    return '<' in s or '>' in s\n",
    "\n",
    "def get_param_value_from_ineq(ref_pft_value,min_val,max_val,pft_ineq):\n",
    "    '''returns the parameter value for the pft that depends on a reference pft value'''\n",
    "    \n",
    "    if contains_angle_brackets(pft_ineq):\n",
    "        if \">\" in pft_ineq:\n",
    "            min_val = ref_pft_value\n",
    "            new_value = np.random.uniform(float(min_val),float(max_val))\n",
    "        if \"<\" in pft_ineq:\n",
    "            max_val = ref_pft_value\n",
    "            new_value = np.random.uniform(float(min_val),float(max_val))\n",
    "    else:\n",
    "        new_value = ref_pft_value\n",
    "    \n",
    "    return new_value\n",
    "\n",
    "def find_duplicates(lst):\n",
    "    count = {}\n",
    "    duplicates = []\n",
    "\n",
    "    for item in lst:\n",
    "        if item in count:\n",
    "            count[item] += 1\n",
    "        else:\n",
    "            count[item] = 1\n",
    "\n",
    "    for key, value in count.items():\n",
    "        if value > 1:\n",
    "            duplicates.append(key)\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "def remove_duplicates(lst):\n",
    "    no_duplicates = []\n",
    "    [no_duplicates.append(x) for x in lst if x not in no_duplicates]\n",
    "    return no_duplicates\n",
    "\n",
    "def add_pft_nums(input_string,numbers):\n",
    "    return [input_string + \"_{}\".format(i) for i in numbers]\n",
    "\n",
    "def add_param_names_for_writing_to_netcdf():\n",
    "    \n",
    "    '''It needs to have all the variable names and indices required to write a netcdf file with the parameter values\n",
    "    The variable names and indices required to write the netcdf file are contained in the column headers, but there are some exceptions:\n",
    "\n",
    "    * fates_leaf_slamax_{1:5} equals fates_leaf_sla25top{1:5}\n",
    "    * fates_allom_d2ca_coefficient_min_{1:5} equals fates_allom_d2ca_coefficient_max_{1:5}\n",
    "    * fates_frag_maxdecomp_{2,3,5} are calcuated as specific fractions of fates_frag_maxdecomp_1\n",
    "    * fates_mort_hf_sm_threshold_{1:5} are the same as fates_mort_hf_sm_threshold_0\n",
    "    * fates_recruit_inter_patch_disp_frac_{1:5} are same as fates_recruit_inter_patch_disp_frac_0\n",
    "    '''\n",
    "     \n",
    "    # These are added so that when we write to netcdf files we can just use the column headers as a guide for\n",
    "    # param name and index\n",
    "    \n",
    "    # add fates_leaf_slamax_{1:5} \n",
    "    slamax = add_pft_nums(\"fates_leaf_slamax\",[1,2,3,4,5])\n",
    "    \n",
    "    # add fates_allom_d2ca_coefficient_min_{1:5}\n",
    "    allom_d2ca = add_pft_nums(\"fates_allom_d2ca_coefficient_min\",[1,2,3,4,5])\n",
    "    \n",
    "    # add fates_frag_maxdecomp_{2,3,5}\n",
    "    maxdecomp = add_pft_nums(\"fates_frag_maxdecomp\",[2,3,5])\n",
    "    \n",
    "    # add fates_mort_hf_sm_threshold_{1:5}\n",
    "    hf = add_pft_nums(\"fates_mort_hf_sm_threshold\",[1,2,3,4,5])\n",
    "    \n",
    "    # add fates_recruit_inter_patch_disp_frac_{1:5}\n",
    "    disp = add_pft_nums(\"fates_recruit_inter_patch_disp_frac\",[1,2,3,4,5])\n",
    "    \n",
    "    return slamax + allom_d2ca + maxdecomp + hf + disp\n",
    "\n",
    "def generate_lhs_df(batch_size, seed, param_ranges):\n",
    "\n",
    "    sampler = qmc.LatinHypercube(d=n_params, seed=seed)\n",
    "    sample = sampler.random(n=batch_size)\n",
    "\n",
    "    # scale to parameter ranges\n",
    "    l_bounds = param_ranges['value_min']\n",
    "    u_bounds = param_ranges['value_max']\n",
    "\n",
    "    scaled_sample = qmc.scale(sample, l_bounds, u_bounds)\n",
    "\n",
    "    print(\"ensemble dimensions:\",scaled_sample.shape)\n",
    "\n",
    "    # Create a dataframe of the LHS ensemble\n",
    "    col_names = [v + \"_\" + str(p) for v,p in zip(param_names,pfts)]\n",
    "    lhs_df = pd.DataFrame(data=scaled_sample,columns=col_names)\n",
    "    \n",
    "    return lhs_df\n",
    "\n",
    "\n",
    "def add_inequality_cols(lhs_df,param_ranges_inequalities):\n",
    "\n",
    "    # Create column names of the inequalities parameters\n",
    "    col_names_inequalities = [v + \"_\" + str(p) for v,p in zip(param_ranges_inequalities[\"param\"],param_ranges_inequalities['pft'])]\n",
    "\n",
    "    # Add columns names for special cases\n",
    "    col_names_inequalities = col_names_inequalities + add_param_names_for_writing_to_netcdf()\n",
    "\n",
    "    col_names_inequalities = remove_duplicates(col_names_inequalities)\n",
    "    \n",
    "    def remove_element(lst, element_to_remove):\n",
    "        return [item for item in lst if item != element_to_remove]\n",
    " \n",
    "    col_names_inequalities = remove_element(col_names_inequalities, \"fates_frag_maxdecomp_0\")\n",
    "    \n",
    "    inequalities_df = pd.DataFrame(np.zeros((lhs_df.shape[0],len(col_names_inequalities))),columns=col_names_inequalities)\n",
    "\n",
    "    # Concatenate the dfs\n",
    "    df = pd.concat([lhs_df,inequalities_df], axis = 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_ref_pft_num(ineq):  \n",
    "    for p in pft_names:\n",
    "        if p in ineq:\n",
    "            return pft_names.index(p) + 1\n",
    "        \n",
    "def generate_parameter_values_for_inequalities(param_ranges_inequalities,df):\n",
    "    \n",
    "    print(\"Adding pft inequalities...\")\n",
    "    \n",
    "    for ensemble_member_row in df.index:\n",
    "    \n",
    "        for i in param_ranges_inequalities.index:\n",
    "\n",
    "            # input data from the inequalities df\n",
    "            d = param_ranges_inequalities.loc[i]\n",
    "\n",
    "            # Make sla max the same as slatop\n",
    "            if d['param'] == \"fates_leaf_slamax\":\n",
    "                for i in range(1,6):\n",
    "                    pft_to_assign_value_to = i\n",
    "                    reference_col = \"fates_leaf_slatop_\" + str(pft_to_assign_value_to)\n",
    "                    target_col = \"fates_leaf_slamax_\" + str(pft_to_assign_value_to)\n",
    "                    reference_val = df.loc[ensemble_member_row,reference_col]\n",
    "                    target_val = reference_val\n",
    "                    df.at[ensemble_member_row,target_col] = target_val\n",
    "                    if i == 1:\n",
    "                        df.at[ensemble_member_row,\"fates_leaf_slamax_0\"] = target_val\n",
    "\n",
    "            # Make d2camin the same as d2ca max\n",
    "            if d['param'] == \"fates_allom_d2ca_coefficient_min\":\n",
    "                for i in range(1,6):\n",
    "                    pft_to_assign_value_to = i\n",
    "                    reference_col = \"fates_allom_d2ca_coefficient_max_\" + str(pft_to_assign_value_to)\n",
    "                    target_col = \"fates_allom_d2ca_coefficient_min_\" + str(pft_to_assign_value_to)\n",
    "                    reference_val = df.loc[ensemble_member_row,reference_col]\n",
    "                    target_val = reference_val\n",
    "                    df.at[ensemble_member_row,target_col] = target_val\n",
    "                    if i == 1:\n",
    "                        df.at[ensemble_member_row,\"fates_allom_d2ca_coefficient_min_0\"] = target_val\n",
    "\n",
    "            # Calculate fates_frag_maxdecomp\n",
    "            if d['param'] == \"fates_frag_maxdecomp\":\n",
    "                col_name_suffix = d['organ']\n",
    "                reference_col = \"fates_frag_maxdecomp_0\"\n",
    "                target_col = \"fates_frag_maxdecomp_\" + str(int(col_name_suffix))\n",
    "                \n",
    "\n",
    "                reference_val = df.loc[ensemble_member_row,reference_col]\n",
    "\n",
    "                target_val = reference_val * d['value_max']\n",
    "\n",
    "                df.at[ensemble_member_row,target_col] = target_val\n",
    "\n",
    "            # Set fates_mort_hf_sm_threshold the same for all pfts\n",
    "            for i in range(1,6):\n",
    "                pft_to_assign_value_to = i\n",
    "                reference_col = \"fates_mort_hf_sm_threshold_0\"\n",
    "                target_col = \"fates_mort_hf_sm_threshold_\" + str(int(pft_to_assign_value_to))\n",
    "                \n",
    "                reference_val = df.loc[ensemble_member_row,reference_col]\n",
    "\n",
    "                target_val = reference_val\n",
    "                \n",
    "                df.at[ensemble_member_row,target_col] = target_val\n",
    "\n",
    "            # Set fates_mort_hf_sm_threshold the same for all pfts\n",
    "            for i in range(1,6):\n",
    "                pft_to_assign_value_to = i\n",
    "                reference_col = \"fates_recruit_inter_patch_disp_frac_0\"\n",
    "                target_col = \"fates_recruit_inter_patch_disp_frac_\" + str(int(pft_to_assign_value_to))\n",
    "                reference_val = df.loc[ensemble_member_row,reference_col]\n",
    "                target_val = reference_val\n",
    "                df.at[ensemble_member_row,target_col] = target_val\n",
    "            \n",
    "            # Set the inequalities\n",
    "            if get_ref_pft_num(d['pft_ineq']) is not None:\n",
    "                pft_to_assign_value_to = d[\"pft\"]\n",
    "                reference_pft_num = get_ref_pft_num(d['pft_ineq'])\n",
    "                reference_col = d['param'] + \"_\" + str(int(reference_pft_num))\n",
    "                reference_val = df.loc[ensemble_member_row,reference_col]\n",
    "                target_col = d['param'] + \"_\" + str(int(pft_to_assign_value_to))\n",
    "                target_val = get_param_value_from_ineq(reference_val,min_val = d['value_min'],\n",
    "                                                       max_val = d['value_max'],pft_ineq = d['pft_ineq'])\n",
    "                df.at[ensemble_member_row,target_col] = target_val\n",
    "                \n",
    "    print(\"Finished adding pft inequalities!\")\n",
    "            \n",
    "\n",
    "def check_na_and_zeros(df):\n",
    "    # Check for NA values in each column\n",
    "    na_count = df.isna().sum()\n",
    "    print(\"NA counts in each column:\")\n",
    "    print(na_count)\n",
    "\n",
    "    # Check for zeros in each column\n",
    "    zero_count = (df == 0).sum()\n",
    "    print(\"\\nZero counts in each column:\")\n",
    "    print(zero_count)\n",
    "    \n",
    "    \n",
    "\n",
    "def get_substring_before_underscore(s):\n",
    "    match = re.search(r'^(.*?)_(?=\\d)', s)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def get_last_number(s):\n",
    "    matches = re.findall(r'\\d+', s)\n",
    "    return int(matches[-1]) if matches else None\n",
    "\n",
    "def assign_var_to_nc(file,var_name,value,index):\n",
    "    \n",
    "    '''\n",
    "    assigns a value to a netcdf for a particular pft and organ\n",
    "    \n",
    "    file = full path to netcdf\n",
    "    var_name = fates parameter name\n",
    "    value = parameter value to add to file\n",
    "    '''\n",
    "    \n",
    "    # open nc file\n",
    "    ncfile = nc.netcdf_file(file, 'a')\n",
    "    \n",
    "    # define param of interest\n",
    "    var = ncfile.variables[var_name]\n",
    "    \n",
    "    # get number of dimensions\n",
    "    ndim = len(var.dimensions)\n",
    "    \n",
    "    if var_name == \"fates_stoich_nitr\":\n",
    "        organ_index = 0\n",
    "        var[organ_index,index] = value\n",
    "    \n",
    "    elif \"fates_leafage_class\" in var.dimensions:\n",
    "        var[:,index] = value\n",
    "   \n",
    "    elif ndim == 0:\n",
    "        \n",
    "        var[...] = value\n",
    "    \n",
    "    else:\n",
    "        var[index] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b2c54-8a51-41ed-ae79-e45cfda92486",
   "metadata": {},
   "source": [
    "## Create LHS without the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb9f563-eb2f-4656-86d9-fd8418bc5e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble dimensions: (2560, 55)\n"
     ]
    }
   ],
   "source": [
    "# Create df of potential parameterizations\n",
    "lhs_df = generate_lhs_df(batch_size, seed, param_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf81489e-1b8b-4316-9ad8-bb2387b95cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_inequality_cols(lhs_df,param_ranges_inequalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b667a8a1-81c4-47b4-ad79-5483a8485660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding pft inequalities...\n",
      "Finished adding pft inequalities!\n"
     ]
    }
   ],
   "source": [
    "generate_parameter_values_for_inequalities(param_ranges_inequalities,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1f83b",
   "metadata": {},
   "source": [
    "## Generate promising ensemble members with the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34c4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_promising = pd.DataFrame()\n",
    "\n",
    "# while len(df_promising) < target_ensemble_size:\n",
    "    \n",
    "#     if len(df_promising) == 0:\n",
    "#         seed = starting_seed\n",
    "#     else:\n",
    "#         seed = seed + 1\n",
    "    \n",
    "#     print(\"LHS seed:\",seed)\n",
    "    \n",
    "#     # Create df of potentail paramterizations\n",
    "#     lhs_df = generate_lhs_df(batch_size, seed, param_ranges)\n",
    "#     df = add_inequality_cols(lhs_df,param_ranges_inequalities)\n",
    "#     generate_parameter_values_for_inequalities(param_ranges_inequalities,df)\n",
    "\n",
    "#     # Check which ones will work\n",
    "#     X = transformation_pipeline.fit_transform(df[X_cols])\n",
    "#     probabilities = DNN_NFailed_PFTs.predict(X)\n",
    "#     y_pred = np.argmax(probabilities, axis=1)\n",
    "#     y_pred_0 = [i == 0 for i in y_pred]\n",
    "#     df_promising = pd.concat([df_promising,df[y_pred_0]])\n",
    "    \n",
    "#     print(len(df_promising), \"promising ensemble members so far...\")\n",
    "#     df_promising_reset = df_promising.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb116785",
   "metadata": {},
   "source": [
    "## Make subdirectories for parameter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "243da1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afterOakFix_2560_042323_01', 'afterOakFix_2560_042323_02', 'afterOakFix_2560_042323_03', 'afterOakFix_2560_042323_04', 'afterOakFix_2560_042323_05', 'afterOakFix_2560_042323_06', 'afterOakFix_2560_042323_07', 'afterOakFix_2560_042323_08', 'afterOakFix_2560_042323_09', 'afterOakFix_2560_042323_10', 'afterOakFix_2560_042323_11', 'afterOakFix_2560_042323_12', 'afterOakFix_2560_042323_13', 'afterOakFix_2560_042323_14', 'afterOakFix_2560_042323_15', 'afterOakFix_2560_042323_16', 'afterOakFix_2560_042323_17', 'afterOakFix_2560_042323_18', 'afterOakFix_2560_042323_19', 'afterOakFix_2560_042323_20']\n"
     ]
    }
   ],
   "source": [
    "param_file_subdirs = []\n",
    "for subdir_i in range(n_cases):\n",
    "    subdir_tag = str(subdir_i+1).rjust(2, '0')\n",
    "    param_file_subdirs.append(param_files_subdir_prefix +\"_\" + subdir_tag)\n",
    "print(param_file_subdirs)\n",
    "\n",
    "for i in range(len(param_file_subdirs)):\n",
    "    os.makedirs(os.path.join(path_to_ensemble_param_files_root,param_file_subdirs[i]),exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0bebc9",
   "metadata": {},
   "source": [
    "## Write promising parameterizations to netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53c21ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/u/home/adamhb/ahb_params/fates_api_25/ca_ahb_5pfts_041624.nc\n",
      "Working on afterOakFix_2560_042323_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/adamhb/tmp/ipykernel_20604/4058855063.py:237: DeprecationWarning: Please use `netcdf_file` from the `scipy.io` namespace, the `scipy.io.netcdf` namespace is deprecated.\n",
      "  ncfile = nc.netcdf_file(file, 'a')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on afterOakFix_2560_042323_02\n",
      "Working on afterOakFix_2560_042323_03\n",
      "Working on afterOakFix_2560_042323_04\n",
      "Working on afterOakFix_2560_042323_05\n",
      "Working on afterOakFix_2560_042323_06\n",
      "Working on afterOakFix_2560_042323_07\n",
      "Working on afterOakFix_2560_042323_08\n",
      "Working on afterOakFix_2560_042323_09\n",
      "Working on afterOakFix_2560_042323_10\n",
      "Working on afterOakFix_2560_042323_11\n",
      "Working on afterOakFix_2560_042323_12\n",
      "Working on afterOakFix_2560_042323_13\n",
      "Working on afterOakFix_2560_042323_14\n",
      "Working on afterOakFix_2560_042323_15\n",
      "Working on afterOakFix_2560_042323_16\n",
      "Working on afterOakFix_2560_042323_17\n",
      "Working on afterOakFix_2560_042323_18\n",
      "Working on afterOakFix_2560_042323_19\n",
      "Working on afterOakFix_2560_042323_20\n"
     ]
    }
   ],
   "source": [
    "#Read in FATES file with values that will be used for all non-varying parameters\n",
    "# This parameter file has many changes associated with it compared to the default FATES file\n",
    "# It also has new parameter added as part of the development required for this experiment.\n",
    "input_fname = os.path.join(path_to_base_param_files_root,base_param_file_name)\n",
    "\n",
    "print(input_fname)\n",
    "\n",
    "# For each sample\n",
    "row = -1\n",
    "\n",
    "# Loop over cases\n",
    "for subdir in param_file_subdirs:\n",
    "    \n",
    "    print(\"Working on\",subdir)\n",
    "    # Loop over instances in the case\n",
    "    for i in range(0,inst_per_case) :\n",
    "        \n",
    "        row = row + 1\n",
    "                \n",
    "        param_file_end = str(i+1).rjust(4, '0')\n",
    "\n",
    "        # final parameter file name\n",
    "        new_file_name = file_name_prefix + '_{0}.nc'.format(param_file_end)\n",
    "        fout = os.path.join(path_to_ensemble_param_files_root,subdir,new_file_name)\n",
    "\n",
    "        shutil.copyfile(input_fname, fout)                                                                                                                             \n",
    "      \n",
    "        # Loop through each parameter and apply either to the correct pft or globally\n",
    "        for col_name in sorted(list(df.columns)): # This was df_promising\n",
    "           \n",
    "            var_name = get_substring_before_underscore(col_name)\n",
    "            \n",
    "            index = max(0,get_last_number(col_name) - 1)\n",
    "            value = df.loc[row, col_name] # This was df_promising_reset\n",
    "            assign_var_to_nc(fout,var_name,value,index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452faa1a-64c9-468f-9fee-c31a2aa87286",
   "metadata": {},
   "source": [
    "## Check distribution of param values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d1182fd-3625-4ae4-bde2-97f6b209f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_param_dist(var = \"fates_allom_crown_depth_frac\",index = 0):\n",
    "\n",
    "    param_range = []\n",
    "    \n",
    "    #Loop through ensemble members\n",
    "    for subdir in param_file_subdirs:\n",
    "        \n",
    "        for inst in range(0,inst_per_case):\n",
    "    \n",
    "            # Get tag\n",
    "            param_file_end = str(inst+1).rjust(4, '0')\n",
    "    \n",
    "            # Get param file with inst tag\n",
    "            ref_nc_file = esm_tools.find_files_with_substring(directory=os.path.join(path_to_ensemble_param_files_root,subdir),\n",
    "                                                    substring=param_file_end)\n",
    "            \n",
    "            # Get full path of ref param file\n",
    "            ref_nc_file_full_path = os.path.join(path_to_ensemble_param_files_root,subdir,ref_nc_file[0])\n",
    "            \n",
    "            param_range.append(esm_tools.extract_variable_from_netcdf(ref_nc_file_full_path,var,index))\n",
    "            #print(param_range[inst])\n",
    "\n",
    "    plt.hist(param_range)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80190937-af6e-4620-a419-733d54989194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_param_dist(var = \"fates_leaf_vcmax25top\",index = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b0b93-e12b-4e99-8809-d1b1f5e38bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env4_work",
   "language": "python",
   "name": "env4_work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
